p8105\_hw3\_dl3157
================
Ditian Li
2018/10/11

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
brfss_sm = brfss_smart2010 %>%
janitor::clean_names() %>%
filter(topic == 'Overall Health') %>%
 mutate(response = as.factor(response),
         response = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) %>% 
  select(year, locationabbr, locationdesc, response, everything()) 

levels(brfss_sm$response)
```

    ## [1] "Excellent" "Very good" "Good"      "Fair"      "Poor"

``` r
brfss_sm %>%
  group_by(year,locationabbr) %>% 
  summarize(n = n_distinct(locationdesc)) %>% 
  filter(n == 7) %>% 
  filter(year == 2002)
```

    ## # A tibble: 3 x 3
    ## # Groups:   year [1]
    ##    year locationabbr     n
    ##   <int> <chr>        <int>
    ## 1  2002 CT               7
    ## 2  2002 FL               7
    ## 3  2002 NC               7

In 2002, CT, FL and NC were observed at 7 locations.

``` r
brfss_sm %>% 
  group_by(year, locationabbr) %>% 
  summarize(n = n_distinct(locationdesc)) %>% 
  ggplot(aes(x = year, y = n, color = locationabbr)) + 
  geom_point() + geom_line(alpha = .7) + 
  labs( title = "locations in each state from 2002 to 2010",
    x = "Year",
    y = "Number of locations") + 
  theme(legend.position = "left")
```

<img src="p8105_hw3_dl3157_files/figure-markdown_github/p1q2-1.png" width="90%" /> comment:

``` r
brfss_sm1 <- brfss_sm %>% 
  spread(key = "response", value = "data_value") %>% 
  janitor::clean_names() %>% 
  select(year, locationabbr, locationdesc, excellent:poor) %>% 
  filter( year %in% c(2002,2006,2010) ) %>% 
  group_by(year, locationdesc) %>% 
  filter(locationdesc == "NY") %>% 
  summarize(mean_excellent = mean(excellent, na.rm = TRUE),
            sd_excellent = sd(excellent, na.rm = TRUE)) %>% 
  knitr::kable(digits = 1)

brfss_sm1
```

|      year| locationdesc |  mean\_excellent|  sd\_excellent|
|---------:|:-------------|----------------:|--------------:|
|  有问题！| 9个          |                 |               |

``` r
brfss_sm %>% 
  spread(key = "response", value = "data_value") %>% 
  janitor::clean_names() %>% 
  select(year, locationabbr, locationdesc, excellent:poor) %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_excellent = mean(excellent, na.rm = TRUE),
            mean_very_good = mean(very_good, na.rm = TRUE),
            mean_good = mean(good, na.rm = TRUE),
            mean_fair = mean(fair, na.rm = TRUE),
            mean_poor = mean(poor, na.rm = TRUE)
            ) %>% 
  gather(key = "mean_response", value = "average_proportion",    
  mean_excellent:mean_poor) %>%
  ggplot(aes(x = year, y = average_proportion, color = locationabbr)) + 
  geom_point() + geom_line() +
  facet_grid(~mean_response) +
  labs(
    title = "Average proportion in each response for each year and each    
    state",
    x = "Year",
    y = "Average proportion"
  ) + theme(legend.position = "none",axis.text.x = element_text(angle = 45))
```

<img src="p8105_hw3_dl3157_files/figure-markdown_github/p1q4-1.png" width="90%" /> comment: 改顺序

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
instacart
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord… reordered user_id eval_set
    ##       <int>      <int>            <int>     <int>   <int> <chr>   
    ##  1        1      49302                1         1  112108 train   
    ##  2        1      11109                2         1  112108 train   
    ##  3        1      10246                3         0  112108 train   
    ##  4        1      49683                4         0  112108 train   
    ##  5        1      43633                5         1  112108 train   
    ##  6        1      13176                6         0  112108 train   
    ##  7        1      47209                7         0  112108 train   
    ##  8        1      22035                8         1  112108 train   
    ##  9       36      39612                1         0   79431 train   
    ## 10       36      19660                2         1   79431 train   
    ## # ... with 1,384,607 more rows, and 9 more variables: order_number <int>,
    ## #   order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

overview: 1384617\*15 key variables 三个id

``` r
instacart %>% 
  group_by(aisle) %>% 
  summarize(n_item = n()) %>% 
  arrange(desc(n_item))
```

    ## # A tibble: 134 x 2
    ##    aisle                         n_item
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

``` r
  head(10)
```

    ## [1] 10

There are 134 aisles in tha instacart dataset, the most items are ordered from fresh vegetables, fresh fruits, packaged vegetables fruits.

``` r
instacart1 <- instacart %>% 
  group_by(aisle) %>% 
  summarize(n_item = n()) %>% 
  mutate(group = as.numeric(cut_number(n_item, 3))) %>% 
  ggplot(aes(x = reorder(aisle, n_item), y = n_item)) +
    geom_point() +
    facet_wrap(group ~ ., nrow = 3, scales = "free") +
    theme(axis.text.x = element_text(size = 6, hjust = 1, angle = 45)) +
    labs(
      title = "Number of Items Ordered in Aisles",
      x = "Aisle Name",
      y = "Number of Items Ordered"
      )
```

comment:

``` r
instacart %>%  
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged     
  vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(count = n()) %>% 
  group_by(aisle) %>% 
  mutate(rank = min_rank(desc(count))) %>%  
  filter(rank < 2)
```

    ## # A tibble: 2 x 4
    ## # Groups:   aisle [2]
    ##   aisle             product_name                               count  rank
    ##   <chr>             <chr>                                      <int> <int>
    ## 1 baking ingredien… Light Brown Sugar                            499     1
    ## 2 dog food care     Snack Sticks Chicken & Rice Recipe Dog Tr…    30     1

comment:疑惑？？？？

``` r
instacart %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = round(mean(order_hour_of_day), digits = 1)) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  spread(key = "product_name", value = "mean_hour") %>% 
  knitr::kable()
```

|    order\_dow|  Coffee Ice Cream|  Pink Lady Apples|
|-------------:|-----------------:|-----------------:|
|             0|              13.8|              13.4|
|             1|              14.3|              11.4|
|             2|              15.4|              11.7|
|             3|              15.3|              14.2|
|             4|              15.2|              11.6|
|             5|              12.3|              12.8|
|             6|              13.8|              11.9|
|  comment:疑惑|              不解|                  |

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
ny_noaa
```

    ## # A tibble: 2,595,176 x 7
    ##    id          date        prcp  snow  snwd tmax  tmin 
    ##    <chr>       <date>     <int> <int> <int> <chr> <chr>
    ##  1 US1NYAB0001 2007-11-01    NA    NA    NA <NA>  <NA> 
    ##  2 US1NYAB0001 2007-11-02    NA    NA    NA <NA>  <NA> 
    ##  3 US1NYAB0001 2007-11-03    NA    NA    NA <NA>  <NA> 
    ##  4 US1NYAB0001 2007-11-04    NA    NA    NA <NA>  <NA> 
    ##  5 US1NYAB0001 2007-11-05    NA    NA    NA <NA>  <NA> 
    ##  6 US1NYAB0001 2007-11-06    NA    NA    NA <NA>  <NA> 
    ##  7 US1NYAB0001 2007-11-07    NA    NA    NA <NA>  <NA> 
    ##  8 US1NYAB0001 2007-11-08    NA    NA    NA <NA>  <NA> 
    ##  9 US1NYAB0001 2007-11-09    NA    NA    NA <NA>  <NA> 
    ## 10 US1NYAB0001 2007-11-10    NA    NA    NA <NA>  <NA> 
    ## # ... with 2,595,166 more rows

``` r
ny_noaa %>% 
  group_by(id) %>% 
  summarize(prcp_na = sum(is.na(prcp)),
            snow_na = sum(is.na(snow)),
            snwd_na = sum(is.na(snwd)),
            tmax_na = sum(is.na(tmax)),
            tmin_na = sum(is.na(tmin)))
```

    ## # A tibble: 747 x 6
    ##    id          prcp_na snow_na snwd_na tmax_na tmin_na
    ##    <chr>         <int>   <int>   <int>   <int>   <int>
    ##  1 US1NYAB0001      60     252     874    1157    1157
    ##  2 US1NYAB0006      19     283     703     852     852
    ##  3 US1NYAB0010     220     352     816     822     822
    ##  4 US1NYAB0016      98     152     212     214     214
    ##  5 US1NYAB0017     301     415     459     459     459
    ##  6 US1NYAB0021       2      37      72     365     365
    ##  7 US1NYAB0022     233     238     239     273     273
    ##  8 US1NYAB0023     144     238     289     365     365
    ##  9 US1NYAB0025      40      43      43     215     215
    ## 10 US1NYAL0002      57     245     409     549     549
    ## # ... with 737 more rows

为啥要加400？

``` r
ny_noaa1 <- ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(prcp = prcp / 10,
         tmax = as.numeric(tmax) / 10,
         tmin = as.numeric(tmin) / 10)
  count(ny_noaa, snow) %>% arrange(desc(n))
```

    ## # A tibble: 282 x 2
    ##     snow       n
    ##    <int>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # ... with 272 more rows

``` r
ny_noaa1 %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = round(mean(tmax, na.rm = TRUE), digits = 1),
            mean_tmin = round(mean(tmin, na.rm = TRUE), digits = 1)) %>% 
  na.omit() %>% 
  gather(key = mean_temp, value = temp, mean_tmax) %>%
  filter(month %in% c("01", "07")) %>% 
  ggplot(aes(x = year, y = temp)) + geom_boxplot() +   
  facet_grid(~month) + 
  theme(axis.text.x = element_text(size = 5, angle = 45),legend.position = "bottom") +
   labs(
    title = "Average max temperature in January and July in each station  
    from 1981 to 2010", x = "Year", y = "Average max temperature in ˚C"
  )
```

<img src="p8105_hw3_dl3157_files/figure-markdown_github/p3q2-1.png" width="90%" />

``` r
ny_noaa2 <- ny_noaa1 %>% 
  ggplot(aes(x = tmax, y = tmin)) + geom_hex()  +
  labs(
    title = "Hex plot of maximum temperature/minimum temperature",
    x = "maximum temperature",
    y = "minimum temperature"
  )
ny_noaa2
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

<img src="p8105_hw3_dl3157_files/figure-markdown_github/p3q4-1.png" width="90%" />

``` r
ny_noaa3 <- ny_noaa1 %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = snow, y = year)) + geom_density_ridges(scale = .8) +
  labs(
    title = "density plot of snowfall from 0 mm to 100 mm across years",
    x = "snow fall in mm", y = "Year")
ny_noaa3
```

    ## Picking joint bandwidth of 3.76

<img src="p8105_hw3_dl3157_files/figure-markdown_github/p3q4-2.png" width="90%" />
